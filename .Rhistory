rf_results_50 <- map_dfr(seeds, rf_cv)
# summary (directly comparable to your XGB results)
rf_results_50 %>%
summarise(
mean_acc = mean(mean_acc)
)
######plotting mean structure #####
# look at F1 and F2 mean structure
vars_formant <- c("sF1", "sF2")
n_bins <- 9
# reload acoustic df
df_formant <- read_csv("/Users/noahkhaloo/Desktop/TTS_perception/data/acoustic_data/output.csv") %>%
mutate(speaker = substr(Filename, 1, 3)) %>%
left_join(ground_truth, by = "speaker") %>%
select(
Filename, Label, seg_Start, seg_End,
sF1, sF2,
speaker, ground_truth_label
) %>%
mutate(
modality = case_when(
str_ends(Label, "_hc") ~ "breathy_creaky",
str_ends(Label, "_c")  ~ "creaky",
str_ends(Label, "_h")  ~ "breathy",
TRUE                   ~ "modal"
),
Label = str_remove(Label, "_(hc|c|h)$")
) %>%
filter(str_detect(Filename, "central|mono|raising|fronting")) %>%
left_join(vowel_codes, by = "Label") %>%
mutate(
gender = substr(Filename, 2, 2),
gender = case_when(
gender == "F" ~ "female",
gender == "M" ~ "male",
TRUE ~ NA_character_
),
vowel = case_when(
vowel %in% c("ɑh", "ah") ~ "ɑ",
vowel == "ih"            ~ "ɪ",
vowel == "ai"            ~ "æi",
vowel %in% c("ɑ'", "a")  ~ "æ",
TRUE ~ vowel
)
) %>%
drop_na(vowel) %>%
filter(
gender == "male",
ground_truth_label != "Ambiguous",
is.finite(sF1),
is.finite(sF2)
)
df_norm9_F12 <- df_formant %>%
group_by(Filename, Label, seg_Start, seg_End) %>%
mutate(
n_ms = n(),
t_norm = ifelse(
n_ms == 1,
0.5,
(row_number() - 1) / (n_ms - 1)
),
t_bin = pmin(n_bins, floor(t_norm * n_bins) + 1)
) %>%
ungroup()
df_token_F12 <- df_norm9_F12 %>%
pivot_longer(
all_of(vars_formant),
names_to = "feature",
values_to = "value"
) %>%
group_by(
Filename, Label, seg_Start, seg_End,
vowel, ground_truth_label, feature, t_bin
) %>%
summarise(
token_mean = mean(value, na.rm = TRUE),
.groups = "drop"
)
df_mean9_F12 <- df_token_F12 %>%
group_by(vowel, ground_truth_label, feature, t_bin) %>%
summarise(
mean_value = mean(token_mean, na.rm = TRUE),
sd_value   = sd(token_mean, na.rm = TRUE),
n_tokens   = sum(!is.na(token_mean)),
se_value   = sd_value / sqrt(n_tokens),
ci_low     = mean_value - 1.96 * se_value,
ci_high    = mean_value + 1.96 * se_value,
.groups = "drop"
) %>%
mutate(
t_norm_center = (t_bin - 0.5) / n_bins,
feature_label = recode(feature, sF1 = "F1", sF2 = "F2")
)
ggplot(
df_mean9_F12,
aes(
x = t_norm_center,
y = mean_value,
color = ground_truth_label,
fill  = ground_truth_label
)
) +
geom_ribbon(
aes(ymin = ci_low, ymax = ci_high),
alpha = 0.2,
color = NA,
show.legend = FALSE
) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
facet_grid(feature_label ~ vowel, scales = "free_y") +
scale_x_continuous(
breaks = seq(0, 1, by = 0.25),
limits = c(0, 1),
labels = scales::label_number(
accuracy = 0.1
)
) +
labs(
x = "Normalized Time",
y = "Mean formant value",
color = "Perceptually-Assigned Race"
) +
guides(fill = "none") +
theme_minimal(base_size = 13) +   # ← FIRST
theme(
## VOWEL labels (top strips)
strip.text.x = element_text(
size = 18,
face = "bold"
),
panel.spacing.x = unit(1.5, "lines"),
strip.text.y = element_text(
size = 18,
face = "bold",
angle = 0
),
strip.placement = "outside",
axis.text.x = element_text(size = 13),
axis.text.y = element_text(size = 14)
)
# plot top voice quality features
df_clean_male <- df_clean %>%
filter(gender == "male")
vars_to_plot <- c("H1Res", "H2KH5Kc", "sF4", "H2H4c", "CPP")
n_bins <- 9
df_norm9 <- df_clean_male %>%
select(Filename, speaker, ground_truth_label, vowel, Label, modality, seg_Start, seg_End,
all_of(vars_to_plot)) %>%
group_by(Filename, Label, seg_Start, seg_End) %>%
mutate(
n_ms = n(),
t_norm = ifelse(n_ms == 1, 0.5, (row_number() - 1) / (n_ms - 1)),
t_bin = pmin(n_bins, floor(t_norm * n_bins) + 1)
) %>%
ungroup()
df_mean9 <- df_norm9 %>%
pivot_longer(all_of(vars_to_plot), names_to = "feature", values_to = "value") %>%
group_by(
Filename, Label, seg_Start, seg_End,
ground_truth_label, feature, t_bin
) %>%
summarise(
token_mean = mean(value, na.rm = TRUE),
.groups = "drop"
) %>%
group_by(ground_truth_label, feature, t_bin) %>%
summarise(
mean_value = mean(token_mean, na.rm = TRUE),
sd_value   = sd(token_mean, na.rm = TRUE),
n_tokens   = sum(!is.na(token_mean)),
se_value   = sd_value / sqrt(n_tokens),
ci_low     = mean_value - 1.96 * se_value,
ci_high    = mean_value + 1.96 * se_value,
.groups = "drop"
) %>%
mutate(
t_norm_center = (t_bin - 0.5) / n_bins
) %>%
mutate(
feature_label = feature %>%
str_replace("^H1Res$", "Residual H1*") %>%
str_replace("^H2KH5Kc$", "H2kHz*–H5kHz*") %>%
str_replace("^H42Kc$", "H4*–H2kHz*") %>%
str_replace("^H2H4c$", "H2*–H4*") %>%
str_replace("sF4", "F4")
)
ggplot(
df_mean9,
aes(
x = t_norm_center,
y = mean_value,
color = ground_truth_label,
fill  = ground_truth_label
)
) +
geom_ribbon(
aes(ymin = ci_low, ymax = ci_high),
alpha = 0.2,
color = NA,
show.legend = FALSE
) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
facet_wrap(~ feature_label, scales = "free_y") +
scale_x_continuous(
breaks = seq(0, 1, by = 0.25),
limits = c(0, 1)
) +
labs(
x = "Normalized Time",
y = "Mean normalized value",
color = "Perceptually-Assigned Race"
) +
guides(fill = "none") +
theme_minimal()
# 1) Create fixed speaker-wise folds (set seed however you like)
folds_df <- make_speaker_folds(
df_chunked_kitchensink,
group_col = "speaker",
nfold = 5,
seed = 1
)
df_cv <- df_chunked_kitchensink %>%
left_join(folds_df, by = "speaker")
# 2) CV function that returns out-of-fold predictions (one row per token)
xgb_groupcv_predictions <- function(df, features,
nrounds = 50,
threshold = 0.5) {
stopifnot("fold" %in% names(df))
X <- as.matrix(df[, features])
y <- df$y
fold_levels <- sort(unique(df$fold))
map_dfr(fold_levels, function(fk) {
test_idx  <- which(df$fold == fk)
train_idx <- setdiff(seq_len(nrow(df)), test_idx)
dtrain <- xgb.DMatrix(X[train_idx, , drop = FALSE], label = y[train_idx])
dtest  <- xgb.DMatrix(X[test_idx,  , drop = FALSE], label = y[test_idx])
mod <- xgboost(
data = dtrain,
nrounds = nrounds,
objective = "binary:logistic",
eval_metric = "logloss",
max_depth = 4,
eta = 0.1,
subsample = 1,
colsample_bytree = 1,
min_child_weight = 1,
gamma = 0,
seed = 999,
nthread = 1,
verbose = 0
)
p <- predict(mod, dtest)
tibble(
speaker  = df$speaker[test_idx],
fold     = fk,
y_true   = y[test_idx],
y_prob   = p,
y_pred   = ifelse(p >= threshold, 1, 0),
correct  = y_pred == y_true
)
})
}
# 3) Run CV predictions using the best config (edit nrounds if needed)
cv_preds <- xgb_groupcv_predictions(
df = df_cv,
features = feature_cols_kitchensink,
nrounds = 50,       # <- set to best_cfg$nrounds if your grid search chose a different value
threshold = 0.5
)
# 4) Speaker-level accuracy table
speaker_accuracy <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens = n(),
accuracy = mean(correct),
.groups = "drop"
) %>%
arrange(accuracy)
speaker_accuracy
# 5) (Optional) Add 95% Wald CI for speaker accuracies (useful if n_tokens varies)
speaker_accuracy_ci <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens = n(),
accuracy = mean(correct),
se = sqrt(accuracy * (1 - accuracy) / n_tokens),
ci_low  = accuracy - 1.96 * se,
ci_high = accuracy + 1.96 * se,
.groups = "drop"
) %>%
arrange(accuracy)
speaker_accuracy_ci
# 6) (Optional) Quick check: overall CV accuracy from these OOF preds
overall_acc <- mean(cv_preds$correct)
overall_acc
overall_acc <- mean(cv_preds$correct)
overall_acc
speaker_auc <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens = n(),
auc = as.numeric(pROC::auc(y_true, y_prob)),
.groups = "drop"
) %>%
arrange(auc)
speaker_auc <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens = n(),
auc = as.numeric(pROC::auc(y_true, y_prob)),
.groups = "drop"
) %>%
arrange(auc)
speaker_accuracy_wilson %>%
ggplot(aes(x = reorder(speaker, accuracy), y = accuracy)) +
geom_point(size = 2) +
geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.15) +
coord_flip() +
labs(x = "Speaker", y = "Out-of-fold accuracy (Wilson 95% CI)") +
theme_minimal()
# Exact (Clopper–Pearson) 95% binomial CI for per-speaker accuracy
speaker_accuracy_ci <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens  = n(),
n_correct = sum(correct),
accuracy  = n_correct / n_tokens,
.groups = "drop"
) %>%
rowwise() %>%
mutate(
ci_low  = binom.test(n_correct, n_tokens)$conf.int[1],
ci_high = binom.test(n_correct, n_tokens)$conf.int[2]
) %>%
ungroup() %>%
arrange(accuracy)
speaker_accuracy_ci
# 1) Create fixed speaker-wise folds (set seed however you like)
folds_df <- make_speaker_folds(
df_chunked_kitchensink,
group_col = "speaker",
nfold = 5,
seed = 1
)
df_cv <- df_chunked_kitchensink %>%
left_join(folds_df, by = "speaker")
# 2) CV function that returns out-of-fold predictions (one row per token)
xgb_groupcv_predictions <- function(df, features,
nrounds = 50,
threshold = 0.5) {
stopifnot("fold" %in% names(df))
X <- as.matrix(df[, features])
y <- df$y
fold_levels <- sort(unique(df$fold))
map_dfr(fold_levels, function(fk) {
test_idx  <- which(df$fold == fk)
train_idx <- setdiff(seq_len(nrow(df)), test_idx)
dtrain <- xgb.DMatrix(X[train_idx, , drop = FALSE], label = y[train_idx])
dtest  <- xgb.DMatrix(X[test_idx,  , drop = FALSE], label = y[test_idx])
mod <- xgboost(
data = dtrain,
nrounds = nrounds,
objective = "binary:logistic",
eval_metric = "logloss",
max_depth = 4,
eta = 0.1,
subsample = 1,
colsample_bytree = 1,
min_child_weight = 1,
gamma = 0,
seed = 999,
nthread = 1,
verbose = 0
)
p <- predict(mod, dtest)
tibble(
speaker  = df$speaker[test_idx],
fold     = fk,
y_true   = y[test_idx],
y_prob   = p,
y_pred   = ifelse(p >= threshold, 1, 0),
correct  = y_pred == y_true
)
})
}
# 3) Run CV predictions using the best config (edit nrounds if needed)
cv_preds <- xgb_groupcv_predictions(
df = df_cv,
features = feature_cols_kitchensink,
nrounds = 50,       # <- set to best_cfg$nrounds if your grid search chose a different value
threshold = 0.5
)
# Exact (Clopper–Pearson) 95% binomial CI for per-speaker accuracy
speaker_accuracy_ci <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens  = n(),
n_correct = sum(correct),
accuracy  = n_correct / n_tokens,
.groups = "drop"
) %>%
rowwise() %>%
mutate(
ci_low  = binom.test(n_correct, n_tokens)$conf.int[1],
ci_high = binom.test(n_correct, n_tokens)$conf.int[2]
) %>%
ungroup() %>%
arrange(accuracy)
speaker_accuracy_ci
# Exact (Clopper–Pearson) 95% binomial CI for per-speaker accuracy
speaker_accuracy_ci <- cv_preds %>%
group_by(speaker) %>%
summarise(
n_tokens  = n(),
n_correct = sum(correct),
accuracy  = n_correct / n_tokens,
.groups = "drop"
) %>%
rowwise() %>%
mutate(
ci_low  = binom.test(n_correct, n_tokens)$conf.int[1],
ci_high = binom.test(n_correct, n_tokens)$conf.int[2]
) %>%
ungroup() %>%
arrange(accuracy)
speaker_accuracy_ci
# add race label from speaker ID
speaker_accuracy_ci <- speaker_accuracy_ci %>%
mutate(
race = case_when(
str_starts(speaker, "WM") ~ "White",
str_starts(speaker, "BM") ~ "Black",
TRUE ~ NA_character_
)
)
# mean accuracy by race (speaker-averaged)
race_mean_accuracy <- speaker_accuracy_ci %>%
group_by(race) %>%
summarise(
n_speakers = n(),
mean_accuracy = mean(accuracy),
sd_accuracy   = sd(accuracy),
.groups = "drop"
)
race_mean_accuracy
# re-fit reduced model
# reuse the SAME df_cv with fixed folds
cv_preds_reduced <- xgb_groupcv_predictions(
df = df_cv,
features = feature_cols_reduced,
nrounds = 50,     # change if your reduced model used a different value
threshold = 0.5
)
ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
n_trials = n(),
.groups = "drop"
)
# re-fit reduced model
cv_preds_top15 <- xgb_groupcv_predictions(
df = df_cv,
features = top15_features,
nrounds = 50,      # same as your reduced model
threshold = 0.5
)
speaker_accuracy_top15 <- cv_preds_top15 %>%
group_by(speaker) %>%
summarise(
n_tokens  = n(),
n_correct = sum(correct),
accuracy  = n_correct / n_tokens,
.groups = "drop"
) %>%
rowwise() %>%
mutate(
ci_low  = binom.test(n_correct, n_tokens)$conf.int[1],
ci_high = binom.test(n_correct, n_tokens)$conf.int[2]
) %>%
ungroup() %>%
arrange(accuracy)
speaker_accuracy_top15
race_accuracy_top15 <- speaker_accuracy_top15 %>%
mutate(
race = case_when(
str_starts(speaker, "WM") ~ "White",
str_starts(speaker, "BM") ~ "Black",
TRUE ~ NA_character_
)
) %>%
group_by(race) %>%
summarise(
n_speakers    = n(),
mean_accuracy = mean(accuracy),
sd_accuracy   = sd(accuracy),
.groups = "drop"
)
race_accuracy_top15
race_mean_accuracy
speaker_accuracy_top15
race_accuracy_top15
speaker_accuracy_top15
race_mean_accuracy
race_accuracy_top15
cite(xgboost)
library(xgboost)
cite(xgboost)
cite("xgboost")
citation(xgboost)
citation("xgboost")
