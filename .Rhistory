ks200_seed_level <- ks200_results %>%
dplyr::group_by(seed) %>%
dplyr::summarise(mean_acc = mean(accuracy), .groups = "drop")
ks200_seed_level %>%
dplyr::summarise(
mean_acc = mean(mean_acc),
sd_acc   = sd(mean_acc),
n_trials = dplyr::n()
)
# ---- Compare 50 vs 200 trees ----
ks50_summary <- ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
sd_acc   = sd(mean_acc)
) %>%
mutate(model = "kitchen_sink_50")
ks200_summary <- ks200_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
sd_acc   = sd(mean_acc)
) %>%
mutate(model = "kitchen_sink_200")
bind_rows(ks50_summary, ks200_summary)
ggplot(
top15_pretty,
aes(x = Gain, y = reorder(Feature_label, Gain))
) +
geom_col(fill = "steelblue") +
labs(
x = "Gain",
y = "Feature"
) +
theme_minimal(base_size = 13)
ks50_summary <- ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc)
) %>%
mutate(model = "kitchen_sink_50")
ks200_summary <- ks200_seed_level %>%
summarise(
mean_acc = mean(mean_acc)
) %>%
mutate(model = "kitchen_sink_200")
bind_rows(ks50_summary, ks200_summary)
ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
sd_acc   = sd(mean_acc),
n_trials = dplyr::n(),
.groups = "drop"
)
ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc)
n_trials = n(),
ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
n_trials = n(),
.groups = "drop"
)
ks_out
bind_rows(ks50_summary, ks200_summary)
top15_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
sd_acc   = sd(mean_acc),
n_trials = n(),
.groups = "drop"
)
top15_seed_level %>%
summarise(
mean_acc = mean(mean_acc)
.groups = "drop"
top15_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
.groups = "drop"
)
ks_seed_level %>%
summarise(
mean_acc = mean(mean_acc),
n_trials = n(),
.groups = "drop"
)
ggplot(
top15_pretty,
aes(x = Gain, y = reorder(Feature_label, Gain))
) +
geom_col(fill = "steelblue") +
labs(
x = "Gain",
y = "Feature"
) +
theme_minimal(base_size = 13)
ggplot(
top15_pretty,
aes(x = Gain, y = reorder(Feature_label, Gain))
) +
geom_col(fill = "steelblue") +
labs(
x = "Gain",
y = "Feature"
) +
theme_minimal(base_size = 13)
xgb_groupcv_score <- function(df, features,
params,
nrounds,
folds_df,          # speaker -> fold mapping
threshold = 0.5) {
df_cv <- df %>% left_join(folds_df, by = "speaker")
if (!("fold" %in% names(df_cv))) stop("folds_df join failed.")
X <- as.matrix(df_cv[, features])
y <- df_cv$y
k <- length(unique(df_cv$fold))
fold_ids <- sort(unique(df_cv$fold))
fold_acc <- purrr::map_dbl(fold_ids, function(fold_k) {
test_idx  <- which(df_cv$fold == fold_k)
train_idx <- setdiff(seq_len(nrow(df_cv)), test_idx)
dtrain <- xgb.DMatrix(X[train_idx, , drop = FALSE], label = y[train_idx])
dtest  <- xgb.DMatrix(X[test_idx,  , drop = FALSE], label = y[test_idx])
bst <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
verbose = 0
)
p <- predict(bst, dtest)
pred <- ifelse(p >= threshold, 1, 0)
mean(pred == y[test_idx])
})
tibble(
mean_acc = mean(fold_acc),
sd_acc_folds = sd(fold_acc)
)
}
param_grid <- tidyr::crossing(
nrounds = c(50, 100, 150, 200, 250, 300),
max_depth = c(2, 3, 4),
eta = c(0.05, 0.1),
subsample = c(0.8, 1.0),
colsample_bytree = c(0.8, 1.0),
min_child_weight = c(1, 5),
gamma = c(0, 1)
)
run_gridsearch_groupcv <- function(df, features,
grid,
nfold = 5,
fold_seed = 1) {
# FIXED folds for all settings
folds_df <- make_speaker_folds(df, group_col = "speaker", nfold = nfold, seed = fold_seed)
results <- purrr::pmap_dfr(grid, function(nrounds, max_depth, eta, subsample,
colsample_bytree, min_child_weight, gamma) {
params <- list(
objective = "binary:logistic",
eval_metric = "error",
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma
)
score <- xgb_groupcv_score(
df = df,
features = features,
params = params,
nrounds = nrounds,
folds_df = folds_df
)
tibble(
nrounds = nrounds,
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma,
mean_acc = score$mean_acc,
sd_acc_folds = score$sd_acc_folds
)
})
results %>% arrange(desc(mean_acc), sd_acc_folds)
}
gs_results <- run_gridsearch_groupcv(
df = df_chunked_kitchensink,
features = feature_cols_kitchensink,
grid = param_grid,
nfold = 5,
fold_seed = 1
)
gs_results %>% slice_head(n = 20)
best <- gs_results %>% slice_max(mean_acc, n = 1)
best
view(best)
# grid search for parameters
xgb_groupcv_score <- function(df, features,
params,
nrounds,
folds_df,
threshold = 0.5) {
df_cv <- df %>% left_join(folds_df, by = "speaker")
if (!("fold" %in% names(df_cv))) stop("folds_df join failed.")
X <- as.matrix(df_cv[, features])
y <- df_cv$y
fold_ids <- sort(unique(df_cv$fold))
# safety defaults (only if not provided)
if (is.null(params$objective))   params$objective   <- "binary:logistic"
if (is.null(params$eval_metric)) params$eval_metric <- "logloss"
fold_acc <- purrr::map_dbl(fold_ids, function(fold_k) {
test_idx  <- which(df_cv$fold == fold_k)
train_idx <- setdiff(seq_len(nrow(df_cv)), test_idx)
dtrain <- xgb.DMatrix(X[train_idx, , drop = FALSE], label = y[train_idx])
dtest  <- xgb.DMatrix(X[test_idx,  , drop = FALSE], label = y[test_idx])
bst <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
verbose = 0
)
p <- predict(bst, dtest)
# If using hinge, predictions are already {0,1}
if (identical(params$objective, "binary:hinge")) {
pred <- as.integer(p)
} else {
pred <- ifelse(p >= threshold, 1, 0)
}
mean(pred == y[test_idx])
})
tibble(
mean_acc = mean(fold_acc),
sd_acc_folds = sd(fold_acc)
)
}
param_grid <- tidyr::crossing(
objective = c("binary:logistic", "binary:hinge"),
eval_metric = c("error", "logloss", "auc"),
nrounds = c(50, 100, 150, 200, 250, 300),
max_depth = c(2, 3, 4),
eta = c(0.05, 0.1),
subsample = c(0.8, 1.0),
colsample_bytree = c(0.8, 1.0),
min_child_weight = c(1, 5),
gamma = c(0, 1)
)
run_gridsearch_groupcv <- function(df, features, grid, nfold = 5, fold_seed = 1) {
folds_df <- make_speaker_folds(df, group_col = "speaker", nfold = nfold, seed = fold_seed)
# drop invalid combinations: auc + hinge doesn't make sense
grid2 <- grid %>%
dplyr::filter(!(objective == "binary:hinge" & eval_metric == "auc"))
results <- purrr::pmap_dfr(grid2, function(objective, eval_metric, nrounds, max_depth, eta,
subsample, colsample_bytree, min_child_weight, gamma) {
params <- list(
objective = objective,
eval_metric = eval_metric,
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma
)
score <- xgb_groupcv_score(
df = df,
features = features,
params = params,
nrounds = nrounds,
folds_df = folds_df
)
tibble(
objective = objective,
eval_metric = eval_metric,
nrounds = nrounds,
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma,
mean_acc = score$mean_acc,
sd_acc_folds = score$sd_acc_folds
)
})
results %>% arrange(desc(mean_acc), sd_acc_folds)
}
gs_results <- run_gridsearch_groupcv(
df = df_chunked_kitchensink,
features = feature_cols_kitchensink,
grid = param_grid,
nfold = 5,
fold_seed = 1
)
# grid search for parameters
xgb_groupcv_score <- function(df, features,
params,
nrounds,
folds_df,
threshold = 0.5) {
df_cv <- df %>% left_join(folds_df, by = "speaker")
if (!("fold" %in% names(df_cv))) stop("folds_df join failed.")
X <- as.matrix(df_cv[, features])
y <- df_cv$y
fold_ids <- sort(unique(df_cv$fold))
# safety defaults (only if not provided)
if (is.null(params$objective))   params$objective   <- "binary:logistic"
if (is.null(params$eval_metric)) params$eval_metric <- "logloss"
fold_acc <- purrr::map_dbl(fold_ids, function(fold_k) {
test_idx  <- which(df_cv$fold == fold_k)
train_idx <- setdiff(seq_len(nrow(df_cv)), test_idx)
dtrain <- xgb.DMatrix(X[train_idx, , drop = FALSE], label = y[train_idx])
dtest  <- xgb.DMatrix(X[test_idx,  , drop = FALSE], label = y[test_idx])
bst <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
verbose = 0
)
p <- predict(bst, dtest)
# If using hinge, predictions are already {0,1}
if (identical(params$objective, "binary:hinge")) {
pred <- as.integer(p)
} else {
pred <- ifelse(p >= threshold, 1, 0)
}
mean(pred == y[test_idx])
})
tibble(
mean_acc = mean(fold_acc),
sd_acc_folds = sd(fold_acc)
)
}
param_grid <- tidyr::crossing(
objective = c("binary:logistic", "binary:hinge"),
eval_metric = c("error", "logloss", "auc"),
nrounds = c(50, 100, 150, 200, 250, 300),
max_depth = c(2, 3, 4),
eta = c(0.05, 0.1),
subsample = c(0.8, 1.0),
colsample_bytree = c(0.8, 1.0),
min_child_weight = c(1, 5),
gamma = c(0, 1)
)
run_gridsearch_groupcv <- function(df, features, grid, nfold = 5, fold_seed = 1) {
folds_df <- make_speaker_folds(df, group_col = "speaker", nfold = nfold, seed = fold_seed)
# drop invalid combinations: auc + hinge doesn't make sense
grid2 <- grid %>%
dplyr::filter(!(objective == "binary:hinge" & eval_metric == "auc"))
results <- purrr::pmap_dfr(grid2, function(objective, eval_metric, nrounds, max_depth, eta,
subsample, colsample_bytree, min_child_weight, gamma) {
params <- list(
objective = objective,
eval_metric = eval_metric,
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma,
seed = 999,
nthread = 1
)
score <- xgb_groupcv_score(
df = df,
features = features,
params = params,
nrounds = nrounds,
folds_df = folds_df
)
tibble(
objective = objective,
eval_metric = eval_metric,
nrounds = nrounds,
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma,
mean_acc = score$mean_acc,
sd_acc_folds = score$sd_acc_folds
)
})
results %>% arrange(desc(mean_acc), sd_acc_folds)
}
gs_results <- run_gridsearch_groupcv(
df = df_chunked_kitchensink,
features = feature_cols_kitchensink,
grid = param_grid,
nfold = 5,
fold_seed = 1
)
gs_results %>% slice_head(n = 20)
# --- GRID SEARCH: fixed objective + logloss, speaker-wise CV ---
library(dplyr)
library(purrr)
library(tidyr)
library(xgboost)
# 1) scorer: speaker-wise CV accuracy (objective/logloss fixed in params)
xgb_groupcv_score <- function(df, features,
params,
nrounds,
folds_df,
threshold = 0.5) {
df_cv <- df %>% left_join(folds_df, by = "speaker")
if (!("fold" %in% names(df_cv))) stop("folds_df join failed (no 'fold' column after join).")
X <- as.matrix(df_cv[, features])
y <- df_cv$y
fold_ids <- sort(unique(df_cv$fold))
fold_acc <- purrr::map_dbl(fold_ids, function(fold_k) {
test_idx  <- which(df_cv$fold == fold_k)
train_idx <- setdiff(seq_len(nrow(df_cv)), test_idx)
dtrain <- xgb.DMatrix(X[train_idx, , drop = FALSE], label = y[train_idx])
dtest  <- xgb.DMatrix(X[test_idx,  , drop = FALSE], label = y[test_idx])
bst <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
verbose = 0
)
p <- predict(bst, dtest)
pred <- ifelse(p >= threshold, 1, 0)
mean(pred == y[test_idx])
})
tibble(
mean_acc = mean(fold_acc),
sd_acc_folds = sd(fold_acc)
)
}
# 2) grid runner: fixed folds for fair comparison across settings
run_gridsearch_groupcv_fixed <- function(df, features,
grid,
nfold = 5,
fold_seed = 1,
xgb_seed = 999,
nthread = 1) {
# fixed speaker folds for all configs
folds_df <- make_speaker_folds(df, group_col = "speaker", nfold = nfold, seed = fold_seed)
purrr::pmap_dfr(grid, function(nrounds, max_depth, eta, subsample,
colsample_bytree, min_child_weight, gamma) {
params <- list(
objective = "binary:logistic",
eval_metric = "logloss",
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma,
seed = xgb_seed,
nthread = nthread
)
score <- xgb_groupcv_score(
df = df,
features = features,
params = params,
nrounds = nrounds,
folds_df = folds_df
)
tibble(
objective = "binary:logistic",
eval_metric = "logloss",
nrounds = nrounds,
max_depth = max_depth,
eta = eta,
subsample = subsample,
colsample_bytree = colsample_bytree,
min_child_weight = min_child_weight,
gamma = gamma,
mean_acc = score$mean_acc,
sd_acc_folds = score$sd_acc_folds
)
}) %>%
arrange(desc(mean_acc), sd_acc_folds)
}
# 3) define a sensible grid (edit as desired)
param_grid <- tidyr::crossing(
nrounds = c(50, 100, 150, 200, 250, 300),
max_depth = c(2, 3, 4),
eta = c(0.05, 0.1),
subsample = c(0.8, 1.0),
colsample_bytree = c(0.8, 1.0),
min_child_weight = c(1, 5),
gamma = c(0, 1)
)
# 4) run the search
gs_results <- run_gridsearch_groupcv_fixed(
df = df_chunked_kitchensink,
features = feature_cols_kitchensink,
grid = param_grid,
nfold = 5,
fold_seed = 1,   # same folds every run
xgb_seed = 999,  # deterministic training
nthread = 1      # deterministic across threads
)
# 5) inspect top configs
gs_results %>% slice_head(n = 20)
# 6) best config
best_cfg <- gs_results %>% slice_max(mean_acc, n = 1)
best_cfg
view(best_cfg)
df_chunked_kitchensink
view(df_chunked_kitchensink)
ggplot(
top15_pretty,
aes(x = Gain, y = reorder(Feature_label, Gain))
) +
geom_col(fill = "steelblue") +
labs(
x = "Gain",
y = "Feature"
) +
theme_minimal(base_size = 13)
